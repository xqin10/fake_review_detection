{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06446cfc",
   "metadata": {},
   "source": [
    "# FAKEREVIEW PROJECT - MP12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f35d0",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "   - Training and testing the different methodology to identify the deceptive review\n",
    "\n",
    "## Methodology\n",
    "   - Machine learning algos\n",
    "   - Deep Learning \n",
    "\n",
    "\n",
    "## WIP - improvements\n",
    "Tried with LightBGM \n",
    "\n",
    "Notable TODOs:\n",
    "- todo 1;\n",
    "- todo 2;\n",
    "- todo 3.\n",
    "\n",
    "## Results\n",
    "   - Achieved 80.6% in Precision and Recall \n",
    "\n",
    "## Suggested next steps\n",
    "   - Try another preprocessing method \n",
    "   - Optimizing the hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-canvas",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Library import\n",
    "We import all the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "facial-convertible",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:41:22.600654Z",
     "start_time": "2021-04-03T00:41:22.595044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 24 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import xgboost as xgb\n",
    "#from catboost import Pool,CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# showing multiple outputs \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "# Initialization\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef,roc_auc_score\n",
    "\n",
    "#import lazypredict\n",
    "#from lazypredict.Supervised import LazyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "completed-entity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:35:54.955597Z",
     "start_time": "2021-04-03T00:35:54.953960Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip3 install pandarallel\n",
    "#!pip3 list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-america",
   "metadata": {},
   "source": [
    "## Local library import\n",
    "We import all the required local libraries libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sudden-nicaragua",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:35:55.158554Z",
     "start_time": "2021-04-03T00:35:55.058240Z"
    }
   },
   "outputs": [],
   "source": [
    "# Include local library paths\n",
    "import sys\n",
    "# sys.path.append('path/to/local/lib') # uncomment and fill to import local libraries\n",
    "\n",
    "# Import local libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-extreme",
   "metadata": {},
   "source": [
    "# Parameter definition\n",
    "We set all relevant parameters for our notebook. By convention, parameters are uppercase, while all the \n",
    "other variables follow Python's guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-provincial",
   "metadata": {},
   "source": [
    "\n",
    "# Data import\n",
    "We retrieve all the required data for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medical-strain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:35.235456Z",
     "start_time": "2021-04-03T00:35:55.160251Z"
    }
   },
   "outputs": [],
   "source": [
    "#read the data\n",
    "deceptive_opinion = pd.read_csv('deceptive-opinion.csv')\n",
    "Yelp_review_sentiments = pd.read_excel('Yelp Labelled Review Dataset with Sentiments and Features.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-atlantic",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "Put here the core of the notebook. Feel free di further split this section into subsections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "religious-cornell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:35.250792Z",
     "start_time": "2021-04-03T00:36:35.236270Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert the label to 0:truthful and 1:deceptive\n",
    "Yelp_review_sentiments['deceptive'] = Yelp_review_sentiments['Spam(1) and Not Spam(0)'].map({1: 'deceptive', 0: 'truthful'})\n",
    "Yelp_review_sentiments['text'] = Yelp_review_sentiments[\"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intended-queens",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:35.430857Z",
     "start_time": "2021-04-03T00:36:35.251839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>hotel</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>truthful</td>\n",
       "      <td>conrad</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>truthful</td>\n",
       "      <td>omni</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>intercontinental</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>Problems started when I booked the InterContin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>The Amalfi Hotel has a beautiful website and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>intercontinental</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>The Intercontinental Chicago Magnificent Mile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>palmer</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>The Palmer House Hilton, while it looks good i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>deceptive</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>negative</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>As a former Chicagoan, I'm appalled at the Ama...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      deceptive             hotel  polarity       source  \\\n",
       "0      truthful            conrad  positive  TripAdvisor   \n",
       "1      truthful             hyatt  positive  TripAdvisor   \n",
       "2      truthful             hyatt  positive  TripAdvisor   \n",
       "3      truthful              omni  positive  TripAdvisor   \n",
       "4      truthful             hyatt  positive  TripAdvisor   \n",
       "...         ...               ...       ...          ...   \n",
       "1595  deceptive  intercontinental  negative        MTurk   \n",
       "1596  deceptive            amalfi  negative        MTurk   \n",
       "1597  deceptive  intercontinental  negative        MTurk   \n",
       "1598  deceptive            palmer  negative        MTurk   \n",
       "1599  deceptive            amalfi  negative        MTurk   \n",
       "\n",
       "                                                   text  \n",
       "0     We stayed for a one night getaway with family ...  \n",
       "1     Triple A rate with upgrade to view room was le...  \n",
       "2     This comes a little late as I'm finally catchi...  \n",
       "3     The Omni Chicago really delivers on all fronts...  \n",
       "4     I asked for a high floor away from the elevato...  \n",
       "...                                                 ...  \n",
       "1595  Problems started when I booked the InterContin...  \n",
       "1596  The Amalfi Hotel has a beautiful website and i...  \n",
       "1597  The Intercontinental Chicago Magnificent Mile ...  \n",
       "1598  The Palmer House Hilton, while it looks good i...  \n",
       "1599  As a former Chicagoan, I'm appalled at the Ama...  \n",
       "\n",
       "[1600 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Product_id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Spam(1) and Not Spam(0)</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Features</th>\n",
       "      <th>deceptive</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-30</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['appetizer tray', 'greek salad', 'main courses']</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-05-05</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['little place', 'soho', 'lamb sandwich', 'soh...</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-12-30</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday. Ãƒ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['snack', 'regular company lunch list']</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>ordered lunch for 15 from Snack last Friday. Ãƒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['beautiful quaint', 'pretty street', 'great p...</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>927</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>Snack is great place for a Ãƒâ€šÃ‚Â casual sit down...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>['snack', 'great place', 'ÃƒÂ¢ casual', 'cold wi...</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>Snack is great place for a Ãƒâ€šÃ‚Â casual sit down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355205</th>\n",
       "      <td>161146</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>The aircondition makes so much noise and its ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>[]</td>\n",
       "      <td>truthful</td>\n",
       "      <td>The aircondition makes so much noise and its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355206</th>\n",
       "      <td>116424</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-27</td>\n",
       "      <td>Even though the pictures show very clean room...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>['clean rooms', 'actual room', 'o clock']</td>\n",
       "      <td>truthful</td>\n",
       "      <td>Even though the pictures show very clean room...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355207</th>\n",
       "      <td>161147</td>\n",
       "      <td>349</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-03-03</td>\n",
       "      <td>Backyard of the hotel is total mess shouldn t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>['backyard', 'total mess shouldn t']</td>\n",
       "      <td>truthful</td>\n",
       "      <td>Backyard of the hotel is total mess shouldn t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355208</th>\n",
       "      <td>97930</td>\n",
       "      <td>349</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>['s room', 'villa suite theough', 'wife s 40th...</td>\n",
       "      <td>truthful</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355209</th>\n",
       "      <td>5260</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>['white furniture', 'angry dog', 'shower drain...</td>\n",
       "      <td>truthful</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355210 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_id  Product_id  Rating       Date  \\\n",
       "0           923           0       3 2014-01-30   \n",
       "1           924           0       3 2011-05-05   \n",
       "2           925           0       4 2011-12-30   \n",
       "3           926           0       4 2012-10-04   \n",
       "4           927           0       4 2014-02-06   \n",
       "...         ...         ...     ...        ...   \n",
       "355205   161146         349       1 2012-10-04   \n",
       "355206   116424         349       1 2013-05-27   \n",
       "355207   161147         349       2 2011-03-03   \n",
       "355208    97930         349       2 2014-07-29   \n",
       "355209     5260         349       1 2013-02-07   \n",
       "\n",
       "                                                   Review  \\\n",
       "0       The food at snack is a selection of popular Gr...   \n",
       "1       This little place in Soho is wonderful. I had ...   \n",
       "2       ordered lunch for 15 from Snack last Friday. Ãƒ...   \n",
       "3       This is a beautiful quaint little restaurant o...   \n",
       "4       Snack is great place for a Ãƒâ€šÃ‚Â casual sit down...   \n",
       "...                                                   ...   \n",
       "355205   The aircondition makes so much noise and its ...   \n",
       "355206   Even though the pictures show very clean room...   \n",
       "355207   Backyard of the hotel is total mess shouldn t...   \n",
       "355208   You When I booked with your company on line y...   \n",
       "355209   My room was dirty and I was afraid to walk ba...   \n",
       "\n",
       "        Spam(1) and Not Spam(0) Sentiment  \\\n",
       "0                             1  Positive   \n",
       "1                             1  Positive   \n",
       "2                             1  Positive   \n",
       "3                             1  Positive   \n",
       "4                             1  Positive   \n",
       "...                         ...       ...   \n",
       "355205                        0  Negative   \n",
       "355206                        0  Negative   \n",
       "355207                        0  Negative   \n",
       "355208                        0  Negative   \n",
       "355209                        0  Negative   \n",
       "\n",
       "                                                 Features  deceptive  \\\n",
       "0       ['appetizer tray', 'greek salad', 'main courses']  deceptive   \n",
       "1       ['little place', 'soho', 'lamb sandwich', 'soh...  deceptive   \n",
       "2                 ['snack', 'regular company lunch list']  deceptive   \n",
       "3       ['beautiful quaint', 'pretty street', 'great p...  deceptive   \n",
       "4       ['snack', 'great place', 'ÃƒÂ¢ casual', 'cold wi...  deceptive   \n",
       "...                                                   ...        ...   \n",
       "355205                                                 []   truthful   \n",
       "355206          ['clean rooms', 'actual room', 'o clock']   truthful   \n",
       "355207               ['backyard', 'total mess shouldn t']   truthful   \n",
       "355208  ['s room', 'villa suite theough', 'wife s 40th...   truthful   \n",
       "355209  ['white furniture', 'angry dog', 'shower drain...   truthful   \n",
       "\n",
       "                                                     text  \n",
       "0       The food at snack is a selection of popular Gr...  \n",
       "1       This little place in Soho is wonderful. I had ...  \n",
       "2       ordered lunch for 15 from Snack last Friday. Ãƒ...  \n",
       "3       This is a beautiful quaint little restaurant o...  \n",
       "4       Snack is great place for a Ãƒâ€šÃ‚Â casual sit down...  \n",
       "...                                                   ...  \n",
       "355205   The aircondition makes so much noise and its ...  \n",
       "355206   Even though the pictures show very clean room...  \n",
       "355207   Backyard of the hotel is total mess shouldn t...  \n",
       "355208   You When I booked with your company on line y...  \n",
       "355209   My room was dirty and I was afraid to walk ba...  \n",
       "\n",
       "[355210 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deceptive_opinion\n",
    "Yelp_review_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitted-fortune",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:36.129765Z",
     "start_time": "2021-04-03T00:36:35.432177Z"
    }
   },
   "outputs": [],
   "source": [
    "#filter deceptive opinion dataset with just text and label\n",
    "sub_deceptive_opinion = deceptive_opinion[[\"deceptive\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "casual-synthetic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:36.930261Z",
     "start_time": "2021-04-03T00:36:36.131645Z"
    }
   },
   "outputs": [],
   "source": [
    "#filter Yelp dataset with just text and label\n",
    "sub_Yelp_review_sentiments = Yelp_review_sentiments[[\"deceptive\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "amended-dylan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:37.031747Z",
     "start_time": "2021-04-03T00:36:36.931084Z"
    }
   },
   "outputs": [],
   "source": [
    "#create the subset for each label \n",
    "sub_Yelp_deceptive = sub_Yelp_review_sentiments[sub_Yelp_review_sentiments[\"deceptive\"] == \"deceptive\"].reset_index(drop = True)\n",
    "sub_Yelp_truthful = sub_Yelp_review_sentiments[sub_Yelp_review_sentiments[\"deceptive\"] == \"truthful\"].reset_index(drop = True).iloc[:36133,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "essential-throat",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:37.052681Z",
     "start_time": "2021-04-03T00:36:37.032567Z"
    }
   },
   "outputs": [],
   "source": [
    "#sub dataset of Yelp with around 36100 observations - balance class\n",
    "concat_data = pd.concat([sub_deceptive_opinion, sub_Yelp_deceptive,sub_Yelp_truthful],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51d9688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73861</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent food and awesome 5 star service from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73862</th>\n",
       "      <td>1</td>\n",
       "      <td>YUMMY. Although I haven't had ramen from many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73863</th>\n",
       "      <td>1</td>\n",
       "      <td>The soup is flavorful and deeply taste behind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73864</th>\n",
       "      <td>1</td>\n",
       "      <td>It was a snowy midweek afternoon that we decid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73865</th>\n",
       "      <td>1</td>\n",
       "      <td>Whether it be rain or shine, this place is alw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73866 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       deceptive                                               text\n",
       "0              1  We stayed for a one night getaway with family ...\n",
       "1              1  Triple A rate with upgrade to view room was le...\n",
       "2              1  This comes a little late as I'm finally catchi...\n",
       "3              1  The Omni Chicago really delivers on all fronts...\n",
       "4              1  I asked for a high floor away from the elevato...\n",
       "...          ...                                                ...\n",
       "73861          1  Excellent food and awesome 5 star service from...\n",
       "73862          1  YUMMY. Although I haven't had ramen from many ...\n",
       "73863          1  The soup is flavorful and deeply taste behind ...\n",
       "73864          1  It was a snowy midweek afternoon that we decid...\n",
       "73865          1  Whether it be rain or shine, this place is alw...\n",
       "\n",
       "[73866 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat_data.to_csv('concat_data.csv',index=False)\n",
    "concat_data = pd.read_csv('concat_data.csv')\n",
    "concat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-berkeley",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T23:13:59.164865Z",
     "start_time": "2021-03-26T23:13:59.037852Z"
    }
   },
   "source": [
    "sub_deceptive_opinion = deceptive_opinion[[\"deceptive\", \"text\"]]\n",
    "sub_Yelp_review_sentiments = Yelp_review_sentiments[[\"deceptive\", \"text\"]]\n",
    "concat_data = pd.concat([sub_deceptive_opinion, sub_Yelp_review_sentiments],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stopped-africa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:37.501096Z",
     "start_time": "2021-04-03T00:36:37.053426Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Make text lowercase, remove text in square brackets,remove links,remove special characters\n",
    "    and remove words containing numbers.\n",
    "    '''\n",
    "    #print(text)\n",
    "    if type(text) is str:\n",
    "        text = text.lower()\n",
    "        text = re.sub('\\[.*?\\]', '', text)\n",
    "        text = re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "        text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "        text = re.sub('<.*?>+', '', text)\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "        text = re.sub('\\n', '', text)\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    else:\n",
    "        text = str(text)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broken-capacity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:37.505231Z",
     "start_time": "2021-04-03T00:36:37.502096Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words('english') + ['u', 'Ã¼', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure','Ã£','Ã¢']\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-therapist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:37.577230Z",
     "start_time": "2021-04-03T00:36:37.506072Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "def stemm_text(text):\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split(' '))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sunrise-bishop",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:37.633418Z",
     "start_time": "2021-04-03T00:36:37.578404Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    # Clean puntuation, urls, and so on\n",
    "    text = clean_text(text)\n",
    "    # Remove stopwords\n",
    "    text = remove_stopwords(text)\n",
    "    # Stemm all the words in the sentence\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split(' '))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incomplete-boost",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:43.435877Z",
     "start_time": "2021-04-03T00:36:37.634694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14beda85e7b84d7ebd0fd5fb1448d5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3078), Label(value='0 / 3078'))), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#preprocessing the text\n",
    "concat_data['cleaned_text']=concat_data['text'].parallel_apply(preprocess_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "macro-pharmacy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:36:43.443951Z",
     "start_time": "2021-04-03T00:36:43.436821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "      <td>stay one night getaway famili thursday tripl a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "      <td>tripl rate upgrad view room less also includ b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "      <td>come littl late final catch review past sever ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "      <td>omni chicago realli deliv front spacious room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "      <td>ask high floor away elev got room pleasant dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73861</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent food and awesome 5 star service from...</td>\n",
       "      <td>excel food awesom star servic moment walk leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73862</th>\n",
       "      <td>1</td>\n",
       "      <td>YUMMY. Although I haven't had ramen from many ...</td>\n",
       "      <td>yummi although ramen mani differ place probabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73863</th>\n",
       "      <td>1</td>\n",
       "      <td>The soup is flavorful and deeply taste behind ...</td>\n",
       "      <td>soup flavor deepli tast behind love system ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73864</th>\n",
       "      <td>1</td>\n",
       "      <td>It was a snowy midweek afternoon that we decid...</td>\n",
       "      <td>snowi midweek afternoon decid drop bowl ramen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73865</th>\n",
       "      <td>1</td>\n",
       "      <td>Whether it be rain or shine, this place is alw...</td>\n",
       "      <td>whether rain shine place alway busi prepar wai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73866 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       deceptive                                               text  \\\n",
       "0              1  We stayed for a one night getaway with family ...   \n",
       "1              1  Triple A rate with upgrade to view room was le...   \n",
       "2              1  This comes a little late as I'm finally catchi...   \n",
       "3              1  The Omni Chicago really delivers on all fronts...   \n",
       "4              1  I asked for a high floor away from the elevato...   \n",
       "...          ...                                                ...   \n",
       "73861          1  Excellent food and awesome 5 star service from...   \n",
       "73862          1  YUMMY. Although I haven't had ramen from many ...   \n",
       "73863          1  The soup is flavorful and deeply taste behind ...   \n",
       "73864          1  It was a snowy midweek afternoon that we decid...   \n",
       "73865          1  Whether it be rain or shine, this place is alw...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0      stay one night getaway famili thursday tripl a...  \n",
       "1      tripl rate upgrad view room less also includ b...  \n",
       "2      come littl late final catch review past sever ...  \n",
       "3      omni chicago realli deliv front spacious room ...  \n",
       "4      ask high floor away elev got room pleasant dec...  \n",
       "...                                                  ...  \n",
       "73861  excel food awesom star servic moment walk leav...  \n",
       "73862  yummi although ramen mani differ place probabl...  \n",
       "73863  soup flavor deepli tast behind love system ser...  \n",
       "73864  snowi midweek afternoon decid drop bowl ramen ...  \n",
       "73865  whether rain shine place alway busi prepar wai...  \n",
       "\n",
       "[73866 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prompt-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_data.to_csv('concatdata2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "supposed-housing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T01:05:11.860236Z",
     "start_time": "2021-04-03T01:05:11.844306Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x=concat_data['cleaned_text']\n",
    "y=concat_data['deceptive']\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ranking-library",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T01:05:12.770764Z",
     "start_time": "2021-04-03T01:05:12.760223Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=.1,random_state =23,stratify=y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=.05,random_state =23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2cbe1a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T01:05:18.165935Z",
     "start_time": "2021-04-03T01:05:13.222860Z"
    }
   },
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "#class LemmaTokenizer(object):\n",
    "    #def __init__(self):\n",
    "        #self.wnl=WordNetLemmatizer()\n",
    "    #def __call__(self,doc):\n",
    "        #return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "    \n",
    "#cv=CountVectorizer(analyzer='word',input='content',stop_words='english', ngram_range=(1,2),max_features=60000,min_df=3,tokenizer=LemmaTokenizer()) #60000 reached 79.6\n",
    "#X_train=cv.fit_transform(X_train)\n",
    "#X_test=cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978cc9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert a collection of text documents to a matrix of token counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(stop_words='english', ngram_range=(1,2),max_features=60000) #60000 reached 79.6\n",
    "X_train=cv.fit_transform(X_train)\n",
    "X_test=cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf9379c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the Countvectorize to compressed pickle file \n",
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "\n",
    "def compressed_pickle(title, data):\n",
    "    with bz2.BZ2File(title + \".pbz2\", \"w\") as f: \n",
    "        cPickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1b3fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compressed_pickle('cvtransform.pkl', cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "based-tribune",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T01:05:20.027590Z",
     "start_time": "2021-04-03T01:05:20.021892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70172,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(70172, 60000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3694, 60000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape\n",
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "impressive-sender",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T01:05:21.738201Z",
     "start_time": "2021-04-03T01:05:21.525283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<70172x60000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3959841 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform a count matrix to a normalized tf or tf-idf representation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(X_train)\n",
    "tfidf_transformer.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3445b7",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fatal-swimming",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T00:45:22.842169Z",
     "start_time": "2021-04-03T00:45:22.839593Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "exceptional-transcript",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1556  287]\n",
      " [ 459 1392]]\n",
      "Accuracy: 0.7980508933405522\n",
      "Macro Precision: 0.8006366781597813\n",
      "Macro Recall: 0.798150784738082\n",
      "Macro F1 score:0.7976520588541965\n",
      "MCC:0.5987823027257537\n",
      "roc_auc:0.7981507847380821\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')   \n",
    "Y_train = Y_train.astype('float32')\n",
    "Y_test = Y_test.astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "model = LGBMClassifier(random_state=24,boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.2, n_estimators=300, device = \"cpu\")\n",
    "\n",
    "LGBMC = model.fit(X_train, Y_train)\n",
    "\n",
    "# Do the prediction\n",
    "y_predict =LGBMC.predict(X_test)\n",
    "print(confusion_matrix(Y_test,y_predict))\n",
    "recall=recall_score(Y_test,y_predict,average='macro')\n",
    "precision=precision_score(Y_test,y_predict,average='macro')\n",
    "f1score=f1_score(Y_test,y_predict,average='macro')\n",
    "accuracy=accuracy_score(Y_test,y_predict)\n",
    "matthews = matthews_corrcoef(Y_test,y_predict) \n",
    "roc_auc = roc_auc_score(Y_test,y_predict,average='macro') \n",
    "print('Accuracy: '+ str(accuracy))\n",
    "print('Macro Precision: '+ str(precision))\n",
    "print('Macro Recall: '+ str(recall))\n",
    "print('Macro F1 score:'+ str(f1score))\n",
    "print('MCC:'+ str(matthews))\n",
    "print('roc_auc:'+ str(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01259ed3",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dd2a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4190e58",
   "metadata": {},
   "source": [
    "Tips:set n_jobs=-1 in random_cv = RandomizedSearchCV(n_jobs=-1) to maximize all cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c869e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=LGBMClassifier(device='cpu', n_estimators=5000,\n",
       "                                            random_state=24),\n",
       "                   param_distributions=[{'boosting_type': ['gbdt', 'dart',\n",
       "                                                           'goss'],\n",
       "                                         'learning_rate': [0.005, 0.1, 0.2],\n",
       "                                         'max_depth': [10, 20, 25],\n",
       "                                         'num_leaves': [10, 30, 50],\n",
       "                                         'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f3c74c142d0>}],\n",
       "                   random_state=314, scoring='roc_auc', verbose=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightBGM_clf = LGBMClassifier(random_state=24,n_estimators=5000, device = \"cpu\")\n",
    "\n",
    "param_distribs = [\n",
    "    { # lightBGM\n",
    "        'learning_rate': [0.005, 0.1, 0.2],\n",
    "        'boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "        'num_leaves': [10, 30,50],\n",
    "        'subsample': sp_uniform(loc=0.2, scale=0.8),\n",
    "        'max_depth': [10, 20, 25]\n",
    "        }]\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(lightBGM_clf, param_distribs, n_iter=10, cv=3,refit=True,\n",
    "                                   random_state=314,verbose=True,scoring='roc_auc')\n",
    "\n",
    "rnd_search_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b35a782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score reached: 0.8738434568482675 with params: {'boosting_type': 'dart', 'learning_rate': 0.1, 'max_depth': 25, 'num_leaves': 30, 'subsample': 0.2450155891961434} \n"
     ]
    }
   ],
   "source": [
    "print('Best score reached: {} with params: {} '.format(rnd_search_cv.best_score_, rnd_search_cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26905f",
   "metadata": {},
   "source": [
    "Best score reached: 0.8738434568482675 with params: {'boosting_type': 'dart', 'learning_rate': 0.1, 'max_depth': 25, 'num_leaves': 30, 'subsample': 0.2450155891961434} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9ccdfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', device='cpu', max_depth=25,\n",
       "               n_estimators=5000, num_leaves=30, random_state=24,\n",
       "               subsample=0.2450155891961434)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "361cd753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', device='cpu', max_depth=25,\n",
       "               n_estimators=5000, num_leaves=30, random_state=24,\n",
       "               subsample=0.2450155891961434)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_params = {'boosting_type': 'dart', 'learning_rate': 0.1, 'max_depth': 25, 'num_leaves': 30, 'subsample': 0.2450155891961434}\n",
    "#LGBMmodel = rnd_search_cv.best_estimator_\n",
    "LGBMmodel = LGBMClassifier(boosting_type='dart', device='cpu', max_depth=25,\n",
    "               n_estimators=5000, num_leaves=30, random_state=24,\n",
    "               subsample=0.2450155891961434)\n",
    "LGBMmodel.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7a112ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1564  279]\n",
      " [ 442 1409]]\n",
      "Accuracy: 0.8048186247969681\n",
      "Macro Precision: 0.8071883283797896\n",
      "Macro Recall: 0.8049132714993552\n",
      "Macro F1 score:0.8044743753143442\n",
      "MCC:0.612097371903196\n",
      "roc_auc:0.8049132714993553\n"
     ]
    }
   ],
   "source": [
    "# Do the prediction\n",
    "y_predict =LGBMmodel.predict(X_test)\n",
    "y_prob = LGBMmodel.predict_proba(X_test)\n",
    "print(confusion_matrix(Y_test,y_predict))\n",
    "recall=recall_score(Y_test,y_predict,average='macro')\n",
    "precision=precision_score(Y_test,y_predict,average='macro')\n",
    "f1score=f1_score(Y_test,y_predict,average='macro')\n",
    "accuracy=accuracy_score(Y_test,y_predict)\n",
    "matthews = matthews_corrcoef(Y_test,y_predict) \n",
    "roc_auc = roc_auc_score(Y_test,y_predict,average='macro') \n",
    "print('Accuracy: '+ str(accuracy))\n",
    "print('Macro Precision: '+ str(precision))\n",
    "print('Macro Recall: '+ str(recall))\n",
    "print('Macro F1 score:'+ str(f1score))\n",
    "print('MCC:'+ str(matthews))\n",
    "print('roc_auc:'+ str(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3798a285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75947906, 0.24052094],\n",
       "       [0.03751174, 0.96248826],\n",
       "       [0.40323909, 0.59676091],\n",
       "       ...,\n",
       "       [0.25773305, 0.74226695],\n",
       "       [0.82143092, 0.17856908],\n",
       "       [0.03164694, 0.96835306]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([24.05209372, 96.24882644, 59.67609068, ..., 74.22669475,\n",
       "       17.85690758, 96.8353063 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing the probability of the label \n",
    "y_prob\n",
    "y_prob[:,1]*100 #prob of deceptive review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ab863",
   "metadata": {},
   "source": [
    "**Note**: The first number represent the prob of label 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41dfb6",
   "metadata": {},
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93497b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# open a file, where you ant to store the data\n",
    "file = open('lightBGM.pkl', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(LGBMmodel, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fb4df5",
   "metadata": {},
   "source": [
    "# Extra code for References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "190639c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'en', 'score': 0.8571396576334295}\n",
      "This is an english text cÃ³ cáº£ tieng viá»‡t {'language': 'vi', 'score': 0.8571415221786176}\n",
      "i hope they could rethink {'language': 'en', 'score': 0.999995906929855}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
    "text = 'This is an english text cÃ³ cáº£ tieng viá»‡t i hope they could rethink '\n",
    "doc = nlp(text)\n",
    "# document level language detection. Think of it like average language of the document!\n",
    "print(doc._.language)\n",
    "# sentence level language detection\n",
    "for sent in doc.sents:\n",
    "   print(sent, sent._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "575485a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.language[\"language\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-looking",
   "metadata": {},
   "source": [
    "# References\n",
    "We report here relevant references:\n",
    "1. author1, article1, journal1, year1, url1\n",
    "2. author2, article2, journal2, year2, url2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
